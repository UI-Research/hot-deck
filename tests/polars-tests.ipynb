{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class defining DYNASIM-FEH file reader.\n",
    "\n",
    "DYNASIM FEH produces three files:\n",
    "\n",
    "    - header file,\n",
    "    - family file, and\n",
    "    - person file.\n",
    "\n",
    "\n",
    "read_feh and save_feh modules define functionality for accessing, processing, and writing files.\n",
    "This module defines classes that can be used to edit those functionalities.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import itertools\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "from xlsxwriter import Workbook\n",
    "import os\n",
    "\n",
    "class HotDeckImputer:\n",
    "    def __init__(self, donor_data:pl.DataFrame, \n",
    "                 imputation_var:str, weight_var:str,\n",
    "                 recipient_data:pl.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize with the dataset. Donor data is the source for the hot deck.\n",
    "        Recipient data is the dataset that will receive the imputation.\n",
    "        \"\"\"\n",
    "        self.donor_data = donor_data.clone()\n",
    "        self.imputation_var = imputation_var\n",
    "        self.weight_var = weight_var\n",
    "        self.recipient_data = recipient_data.clone()\n",
    "\n",
    "        # Cell definition attributes to be defined in methods\n",
    "        self.cell_definitions = None\n",
    "        self.donor_cells = None\n",
    "        self.recipient_cells = None\n",
    "\n",
    "        # Random noise attributes defined in methods\n",
    "        self.random_noise = None\n",
    "\n",
    "        # Validate input data\n",
    "        self._validate_data()\n",
    "\n",
    "    def _validate_data(self):\n",
    "            \"\"\"\n",
    "            Validate the input data and parameters.\n",
    "            \"\"\"\n",
    "            # Check for non-empty DataFrames\n",
    "            if self.donor_data.is_empty():\n",
    "                raise ValueError(\"Donor data is empty\")\n",
    "            if self.recipient_data.is_empty():\n",
    "                raise ValueError(\"Recipient data is empty\")\n",
    "            \n",
    "            # Check for imputation variable's presence on both sides\n",
    "            if self.imputation_var not in self.donor_data.columns:\n",
    "                raise ValueError(f\"Column '{self.imputation_var}' is missing from donor data\")\n",
    "            if self.imputation_var in self.recipient_data.columns:\n",
    "                raise ValueError(f\"Column '{self.imputation_var}' is already in recipient data, does not need to be imputed\")\n",
    "            \n",
    "            # Check for weight variables + missingness if weighted imputation is requiured\n",
    "            if self.weight_var is not None:\n",
    "                if self.weight_var not in self.donor_data.columns:\n",
    "                    raise ValueError(f\"Column '{self.weight_var}' is missing from donor data\")\n",
    "                if self.weight_var not in self.recipient_data.columns:\n",
    "                    raise ValueError(f\"Column '{self.weight_var}' is missing from recipient data\")\n",
    "\n",
    "                # Check for missing values in required columns\n",
    "                if self.donor_data[self.weight_var].null_count() > 0:\n",
    "                    raise ValueError(f\"Column '{self.weight_var}' in donor data contains {self.donor_data[self.weight_var].null_count()} missing values\")\n",
    "                if self.recipient_data[self.weight_var].null_count() > 0:\n",
    "                    raise ValueError(f\"Column '{self.weight_var}' in recipient data contains {self.recipient_data[self.weight_var].null_count()} missing values\")\n",
    "                \n",
    "            return\n",
    "            \n",
    "    def _parse_condition(self, condition):\n",
    "        \"\"\"\n",
    "        Parse a condition string and return a Polars expression.\n",
    "\n",
    "        Args:\n",
    "            condition (str): The condition string to parse.\n",
    "\n",
    "        Returns:\n",
    "            pl.Expr: The Polars expression.\n",
    "        \"\"\"\n",
    "        # Remove outer parentheses\n",
    "        condition = condition.strip(\"()\")\n",
    "        \n",
    "        # Split the condition into individual criteria\n",
    "        criteria = condition.split(\" & \")\n",
    "        \n",
    "        # Initialize combined expression with a default \"true\" condition\n",
    "        combined_expression = pl.lit(True)\n",
    "        \n",
    "        # Parse each criterion and combine them using logical AND\n",
    "        for criterion in criteria:\n",
    "            # Remove any extra parentheses and spaces\n",
    "            criterion = criterion.strip(\"()\").strip()\n",
    "            column, value = criterion.split(\"==\")\n",
    "            column = column.strip()\n",
    "            value = value.strip().strip(\"'\")\n",
    "            # Detect the type of the value\n",
    "            if value.isdigit():\n",
    "                value = int(value)\n",
    "            elif value.replace('.', '', 1).isdigit():\n",
    "                value = float(value)\n",
    "            expr = pl.col(column) == value\n",
    "            # Combine the expressions\n",
    "            print(expr)\n",
    "            combined_expression &= expr\n",
    "        \n",
    "        return combined_expression\n",
    "\n",
    "    def generate_cells(self):\n",
    "        \"\"\"\n",
    "        Method to generate cells based on cell definitions.\n",
    "        It splits the data according to the conditions provided in the cell_definitions.\n",
    "        \"\"\"\n",
    "        if not self.cell_definitions:\n",
    "            raise ValueError(\"Cell definitions are not provided\")\n",
    "\n",
    "        # Create empty dictionary to store the partitions\n",
    "        donor_cells = {}\n",
    "        recipient_cells = {}\n",
    "        \n",
    "        for i, condition in enumerate(self.cell_definitions):\n",
    "            # Create cell based on condition\n",
    "            filter_expr = self._parse_condition(condition)\n",
    "            # Filter the donor and recipient data based on the condition\n",
    "            donor_cells[f'{condition}'] = self.donor_data.filter(filter_expr)\n",
    "            recipient_cells[f'{condition}'] = self.recipient_data.filter(filter_expr)\n",
    "\n",
    "        self.donor_cells = donor_cells\n",
    "        self.recipient_cells = recipient_cells\n",
    "        return\n",
    "    \n",
    "    def _check_variable_consistency(self, variables):\n",
    "        \"\"\"\n",
    "        Non-callable method to check if the unique values and types of the variables\n",
    "        are the same in donor and recipient datasets.\n",
    "        :param variables: List of variables to check\n",
    "        :raises TypeError: If data types do not match between donor and recipient\n",
    "        :raises ValueError: If unique values do not match between donor and recipient\n",
    "        \"\"\"\n",
    "        for var in variables:\n",
    "            donor_unique = self.donor_data[var].unique()\n",
    "            recipient_unique = self.recipient_data[var].unique()\n",
    "\n",
    "            # Check if the types match\n",
    "            if self.donor_data[var].dtype != self.recipient_data[var].dtype:\n",
    "                raise TypeError(f\"Data types for variable '{var}' do not match between donor and recipient datasets.\")\n",
    "            \n",
    "            # Check if the unique values match\n",
    "            if set(donor_unique) != set(recipient_unique):\n",
    "                raise ValueError(f\"Unique values for variable '{var}' do not match between donor and recipient datasets.\")\n",
    "\n",
    "    def define_cells(self, variables):\n",
    "        \"\"\"\n",
    "        Method to define all possible cell definitions given a list of input variables.\n",
    "        :param variables: A list of column names (variables) from the data to partition by.\n",
    "        For example: ['homeowner_hh_flag', 'member_over_60']\n",
    "        :return: A list of strings representing all possible conditions\n",
    "        \"\"\"\n",
    "        # First, check if the variables are consistent across donor and recipient datasets\n",
    "        self._check_variable_consistency(variables)\n",
    "\n",
    "        # Extract unique values from the donor data for each variable\n",
    "        var_values = {var: self.donor_data[var].unique() for var in variables}\n",
    "\n",
    "        # Generate all possible combinations of variable values\n",
    "        var_combinations = list(itertools.product(*var_values.values()))\n",
    "\n",
    "        # Create the condition strings\n",
    "        cell_definitions = []\n",
    "        for combination in var_combinations:\n",
    "            conditions = [\n",
    "            f\"{variables[i]} == '{combination[i]}'\" if isinstance(combination[i], str) else f\"{variables[i]} == {combination[i]}\"\n",
    "            for i in range(len(combination))\n",
    "            ]\n",
    "            cell_definitions.append(' & '.join(conditions))\n",
    "\n",
    "        self.cell_definitions = cell_definitions\n",
    "        return \n",
    "\n",
    "    def split_cell(self, cell_condition, split_column):\n",
    "        \"\"\"\n",
    "        Method to split an individual cell further based on a new condition.\n",
    "        :param cell_condition: A condition string representing the cell to be split.\n",
    "        :param split_column: The column to check for unique values to split the cell.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # Get the data for the cell that is going to be split\n",
    "        split_donor = self.donor_cells[cell_condition]\n",
    "        split_recipient = self.recipient_cells[cell_condition]\n",
    "        \n",
    "        # Get unique values in the split column\n",
    "        unique_values = split_donor.select(split_column).unique().to_series().to_list()\n",
    "        \n",
    "        # Remove the original cell from the donor and recipient cell dictionaries\n",
    "        del self.donor_cells[cell_condition]\n",
    "        del self.recipient_cells[cell_condition]\n",
    "\n",
    "        # Split the cell based on unique values in the split column\n",
    "        for value in unique_values:\n",
    "            split_condition = f\"{split_column} == {value}\"\n",
    "            combined_condition = f\"{cell_condition} & {split_condition}\"\n",
    "            split_expr = self._parse_condition(combined_condition)\n",
    "            \n",
    "            # Add the newly split cells into the dictionaries\n",
    "            self.donor_cells[combined_condition] = split_donor.filter(split_expr)\n",
    "            self.recipient_cells[combined_condition] = split_recipient.filter(split_expr)\n",
    "            \n",
    "            # Update cell definitions\n",
    "            self.cell_definitions.append(combined_condition)\n",
    "        \n",
    "        # Remove the original cell condition from cell definitions\n",
    "        self.cell_definitions.remove(cell_condition)\n",
    "        return\n",
    "    \n",
    "    def summarize_cells(self):\n",
    "        results = {}\n",
    "        for i, recipient_cell in self.recipient_cells.items():\n",
    "\n",
    "            # Donor stat generation\n",
    "            donor_cell = self.donor_cells.get(i)\n",
    "            source_var = donor_cell[self.imputation_var]\n",
    "\n",
    "            if self.weight_var in donor_cell.columns:\n",
    "                donor_stats = DescrStatsW(source_var, weights=donor_cell[self.weight_var], ddof=0)\n",
    "            else:\n",
    "                donor_stats = DescrStatsW(source_var, ddof=0)\n",
    "\n",
    "            # Recipient stat generation\n",
    "            source_var = recipient_cell[f'imp_{self.imputation_var}']\n",
    "            if self.weight_var in recipient_cell.columns:\n",
    "                recipient_stats = DescrStatsW(source_var, weights=recipient_cell[self.weight_var], ddof=0)\n",
    "            else:\n",
    "                recipient_stats = DescrStatsW(source_var, ddof=0)\n",
    "\n",
    "            data = {\n",
    "                'statistic': [\n",
    "                    '95int_low', 'mean', '95int_high', 'stddev', 'var', 'stderr', 'sum', 'obs'\n",
    "                ],\n",
    "                'donor': [\n",
    "                    donor_stats.mean - 1.96 * donor_stats.std_mean,  # 95% CI low for donor\n",
    "                    donor_stats.mean,                                # Mean for donor\n",
    "                    donor_stats.mean + 1.96 * donor_stats.std_mean,  # 95% CI high for donor\n",
    "                    donor_stats.std,                                 # Stddev for donor\n",
    "                    donor_stats.var,                                 # Variance for donor\n",
    "                    donor_stats.std_mean,                            # Std error for donor\n",
    "                    donor_stats.sum_weights,                         # Weighted sum for donor\n",
    "                    np.float64(donor_cell.shape[0])                  # Observations for donor\n",
    "                ],\n",
    "\n",
    "                'imp': [\n",
    "                    recipient_stats.mean - 1.96 * recipient_stats.std_mean,  # 95% CI low for imp\n",
    "                    recipient_stats.mean,                                    # Mean for imp\n",
    "                    recipient_stats.mean + 1.96 * recipient_stats.std_mean,  # 95% CI high for imp\n",
    "                    recipient_stats.std,                                     # Stddev for imp\n",
    "                    recipient_stats.var,                                     # Variance for imp\n",
    "                    recipient_stats.std_mean,                                # Std error for imp\n",
    "                    recipient_stats.sum_weights,                             # Weighted sum for imp\n",
    "                    np.float64(recipient_cell.shape[0])                      # Observations for imp\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            # Convert dictionary to DataFrame\n",
    "            stats_df = pl.DataFrame(data)\n",
    "            stats_df = stats_df.with_columns((stats_df['imp'] - stats_df['donor']).alias('diff'))\n",
    "            stats_df = stats_df.with_columns((stats_df['imp']/stats_df['donor']).alias('imp_to_donor_ratio'))\n",
    "\n",
    "            results[i] = stats_df\n",
    "\n",
    "        return results\n",
    "\n",
    "    def gen_analysis_file(self, out_file:str, out_path:str =''):\n",
    "        \"\"\"\n",
    "        Generate an analysis file summarizing the imputation results.\n",
    "        :param out_file (str): Name of the output file.\n",
    "        :param out_path (str): Path to save the output file.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if out_path == '':\n",
    "            out_path = '.'\n",
    "        # Ensure the output directory exists\n",
    "        if not os.path.exists(out_path):\n",
    "            raise FileNotFoundError(f\"The directory '{out_path}' does not exist.\")\n",
    "\n",
    "        # Construct the full file path\n",
    "        full_path = os.path.join(out_path, f'{out_file}.xlsx')\n",
    "\n",
    "        # Get dictionary of DFs for each cell\n",
    "        data = self.summarize_cells()\n",
    "        \n",
    "        # Get iterator for worksheet locations\n",
    "        row = 1\n",
    "        col = 0\n",
    "\n",
    "        # Iterate through each cell's data\n",
    "        with Workbook(full_path) as wb:  \n",
    "            ws = wb.add_worksheet('Summary')\n",
    "            for key, df in data.items():\n",
    "                ws.write(row-1, col, key)\n",
    "                # Write table to excel  \n",
    "                df.write_excel(workbook = wb, \n",
    "                               worksheet = ws,\n",
    "                               position = (row, col),\n",
    "                               table_style=\"Table Style Light 1\",\n",
    "                               autofit = True)\n",
    "            \n",
    "                # 2 row gap between each DF's results\n",
    "                row = row + df.shape[0] + 3\n",
    "        print(f\"Cell data written to '{out_path}\\\\{out_file}.xlsx'.\")\n",
    "\n",
    "    def apply_random_noise(self, variation_stdev, floor_noise = None):\n",
    "        \"\"\"\n",
    "        Add random noise to smooth out issue of clustering\n",
    "            * Within each cell, sort by asset value in donor data \n",
    "            * Get a lagged variable for each row showing asset value of next neighbor\n",
    "            * Compute for the whole cell, the average distance between asset values and their neighbors.\n",
    "            * Add noise to every recipient- a RV with mean 0 and standard deviation of 1/6th of the mean distance for that cell\n",
    "        \"\"\"\n",
    "        imputed_recipient_cells = []\n",
    "\n",
    "        for condition, donor_cell in self.donor_cells.items():\n",
    "            # Sort donor cell by asset value\n",
    "            donor_cell = donor_cell.sort(by=self.imputation_var)\n",
    "\n",
    "            # Calculate the next neighbor values\n",
    "            donor_cell = donor_cell.with_columns(\n",
    "                donor_cell[self.imputation_var].shift(-1).alias('next_val')\n",
    "            )\n",
    "\n",
    "            # Compute the distance to prior and next neighbor\n",
    "            donor_cell = donor_cell.with_columns(\n",
    "                (donor_cell['next_val'] - donor_cell[self.imputation_var]).alias('next_distance')\n",
    "            )\n",
    "            \n",
    "            # Calculate the average neighbor distance for the cell, ignoring NaN values\n",
    "            ## First get mean of each row and then get mean of the result\n",
    "            mean_distance = donor_cell['next_distance'].mean()\n",
    "\n",
    "            # Calculate noise level as a proportion of the mean distance between neighbors\n",
    "            noise_stdev = mean_distance * variation_stdev\n",
    "\n",
    "            # Calculate the threshold value based on relevant floor for asset tests\n",
    "            if floor_noise is not None:\n",
    "                threshold = floor_noise\n",
    "            else:\n",
    "                threshold = self.donor_data[f'{self.imputation_var}'].min()\n",
    "\n",
    "            # Generate random noise for each recipient in the cell\n",
    "            # Only apply this random noise for those who are less than some factor of the standard deviation of neighboring distances\n",
    "            # i.e. if floor_stdev_multiplier = 2, observations with <2x the standard deviation of neighboring distances are left alone\n",
    "            recipient_cell = self.recipient_cells[condition]\n",
    "\n",
    "            # identify the observations who are above the threshold, who will have random noise added\n",
    "            # when there is no thresholding by floor_stdev_multiplier, this is handled by the minimum identified above\n",
    "            ge_thresh = recipient_cell[f'imp_{self.imputation_var}'] >= threshold\n",
    "            noise = np.random.normal(loc=0, scale=noise_stdev, size=recipient_cell.shape[0])\n",
    "            \n",
    "            # Indicate to user that noise was not generated if all values are below the threshold\n",
    "            if ge_thresh.sum() == 0:\n",
    "                print(f'\\nCell:\\n{condition}')\n",
    "                print(f'NO NOISE GENERATED for cell due to thresholding.\\n' \n",
    "                        f'All values are below the threshold of {threshold}\\n'\n",
    "                        f'Mean value of cell observations for imp_{self.imputation_var}: ' \n",
    "                        f'{recipient_cell[f'imp_{self.imputation_var}'].mean()}')\n",
    "\n",
    "            # Apply noise to the imputed liquid assets in the recipient cell\n",
    "            recipient_cell = recipient_cell.with_columns(\n",
    "                pl.when(ge_thresh)\n",
    "                .then(pl.col(f'imp_{self.imputation_var}') + noise)\n",
    "                .otherwise(pl.col(f'imp_{self.imputation_var}'))\n",
    "                .alias(f'imp_{self.imputation_var}')\n",
    "            )\n",
    "\n",
    "            # Ensure that values that have noise applied are not below the minimum donor value\n",
    "            min_donor_val = donor_cell[self.imputation_var].min()\n",
    "            recipient_cell = recipient_cell.with_columns(\n",
    "                pl.col(f'imp_{self.imputation_var}')\n",
    "                .clip(lower_bound = min_donor_val)\n",
    "                .alias(f'imp_{self.imputation_var}')\n",
    "            )\n",
    "\n",
    "            # Update recipient data with noisy values\n",
    "            self.recipient_cells[condition] = recipient_cell.with_columns(\n",
    "                pl.col(f'imp_{self.imputation_var}')\n",
    "            )\n",
    "            imputed_recipient_cells.append(recipient_cell)\n",
    "        # Store the variation standard deviation parameter\n",
    "        self.random_noise = variation_stdev\n",
    "        self.recipient_data = pl.concat(imputed_recipient_cells)\n",
    "        \n",
    "        return\n",
    "\n",
    "    def summarize_column(self, data, column_name):\n",
    "        \"\"\"\n",
    "        Summarize a column in data, returning basic statistics.\n",
    "        :param column_name: The column to summarize\n",
    "        :return: A dictionary with summary statistics\n",
    "        \"\"\"\n",
    "        # Check if the column exists in the DataFrame\n",
    "        if column_name not in data.columns:\n",
    "            raise ValueError(f\"Column '{column_name}' does not exist in donor_data.\")\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        summary_stats = {\n",
    "            'mean': data[column_name].mean(),\n",
    "            'median': data[column_name].median(),\n",
    "            'min': data[column_name].min(),\n",
    "            'max': data[column_name].max(),\n",
    "            'std_dev': data[column_name].std(),\n",
    "            'count': data[column_name].count(),\n",
    "            'missing_values': data[column_name].is_null().sum()\n",
    "        }\n",
    "\n",
    "        return summary_stats\n",
    "\n",
    "    def age_dollar_amounts(self, donor_year_cpi, imp_year_cpi):\n",
    "        \"\"\"\n",
    "        Age the imputed values to the target year. Relevant when the source data and target data differ.\n",
    "        https://www.cbo.gov/data/budget-economic-data#4 for CPI indexes\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f'Summary of {self.imputation_var} pre CPI aging:\\n{self.summarize_column(self.donor_data, self.imputation_var)}')\n",
    "        scaling_factor = imp_year_cpi / donor_year_cpi\n",
    "\n",
    "        self.donor_data = self.donor_data.with_columns(\n",
    "            (pl.col(self.imputation_var) * scaling_factor).alias(self.imputation_var)\n",
    "        )\n",
    "        print(f'Summary of {self.imputation_var} post CPI aging:\\n{self.summarize_column(self.donor_data, self.imputation_var)}')\n",
    "\n",
    "        return\n",
    "\n",
    "    def impute(self):\n",
    "        \"\"\"\n",
    "        Impute the missing values in the recipient data using the donor data for corresponding cells.\n",
    "        This method assumes that both donor and recipient data have been partitioned using generate_cells.\n",
    "        \"\"\"\n",
    "        if not self.cell_definitions:\n",
    "            raise ValueError(\"Cell definitions are not provided\")\n",
    "        \n",
    "        # List to hold imputed recipient cells\n",
    "        imputed_recipient_cells = []\n",
    "\n",
    "        # For each recipient cell, find the corresponding donor cell and perform imputation\n",
    "        for condition, recipient_cell in self.recipient_cells.items():\n",
    "            donor_cell = self.donor_cells.get(condition)\n",
    "            \n",
    "            if donor_cell is not None and not donor_cell.shape[0] == 0:\n",
    "                # Perform weighted random selection for the required number of values\n",
    "                if self.weight_var:\n",
    "                    weights = donor_cell[self.weight_var]\n",
    "                    donor_values = donor_cell[self.imputation_var].drop_nulls()\n",
    "\n",
    "                    # Randomly select `missing_count` values from the donor set using the weights\n",
    "                    # Using weighted selection according to probability proportional to weights https://documentation.sas.com/doc/en/statcdc/14.2/statug/statug_surveyimpute_details25.htm#statug.surveyimpute.weightedDet\n",
    "                    selected_values = np.random.choice(donor_values, size=len(recipient_cell), replace=True, p=weights / weights.sum())\n",
    "                else:\n",
    "                    # Without weights, simply sample donor values\n",
    "                    donor_values = donor_cell[self.imputation_var].drop_nulls()\n",
    "                    selected_values = np.random.choice(donor_values, size=len(recipient_cell), replace=True)\n",
    "\n",
    "                # Add the imputed values to the recipient cell\n",
    "                recipient_cell = recipient_cell.with_columns(\n",
    "                    pl.Series(f'imp_{self.imputation_var}', selected_values)\n",
    "                )\n",
    "                # Add the imputed recipient cell to the list\n",
    "                imputed_recipient_cells.append(recipient_cell)\n",
    "                self.recipient_cells[condition] = recipient_cell.clone()\n",
    "\n",
    "            else:\n",
    "                # If no donors are available, imputation is not performed (or can apply other fallback logic here)\n",
    "                print(f\"No donors available for {condition}, global mean applied\")\n",
    "                recipient_cell[f'imp_{self.imputation_var}'] = np.average(self.donor_data[self.imputation_var], \n",
    "                                                                          self.donor_data[self.weight_var])\n",
    "\n",
    "                # Add the imputed recipient cell to the list\n",
    "                imputed_recipient_cells.append(recipient_cell)\n",
    "                self.recipient_cell = recipient_cell.clone()\n",
    "\n",
    "        # Combine all the imputed recipient cells into one DataFrame\n",
    "        self.recipient_data = pl.concat(imputed_recipient_cells)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_data = {\n",
    "    'donor_assets': [5000000, 20000, 300000, 200000, \n",
    "                     100000, 10000, 200, 200000, 4000, 500000],\n",
    "    'race_cell': ['Black','Black','Black','White','White',\n",
    "                     'White','Black','White','Black','Black'],\n",
    "    'sex_cell': ['M','F','F','M','F',\n",
    "                     'M','F','F','M','F'],\n",
    "    'work_cell': [1,0,1,0,1,\n",
    "                     0,1,1,1,0],\n",
    "    'weight': [1, 2, 1, 2, 1,\n",
    "               2, 1, 2, 1, 2]\n",
    "}\n",
    "\n",
    "donor_data = pl.DataFrame(donor_data)\n",
    "\n",
    "recipient_data = {\n",
    "    'race_cell': ['Black','Black','Black','White','White',\n",
    "                     'White','Black','White','Black','Black','Black','Black','White','White'],\n",
    "    'sex_cell': ['M','F','F','M','F',\n",
    "                     'M','F','F','M','F', 'F', 'M', 'M', 'F'],\n",
    "    'work_cell': [1,0,1,0,1,\n",
    "                     0,1,1,1,0,0,1,0,1],\n",
    "    'weight': [1, 3, 2, 3, 2,\n",
    "               1, 4, 2, 1, 3, 4, 2, 1, 1]\n",
    "}\n",
    "\n",
    "recipient_data = pl.DataFrame(recipient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = HotDeckImputer(donor_data = donor_data, \n",
    "                         imputation_var = 'donor_assets', \n",
    "                         weight_var = 'weight', \n",
    "                         recipient_data = recipient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of donor_assets pre CPI aging:\n",
      "{'mean': 633420.0, 'median': 150000.0, 'min': 200, 'max': 5000000, 'std_dev': 1542663.896425055, 'count': 10, 'missing_values': 0}\n",
      "Summary of donor_assets post CPI aging:\n",
      "{'mean': 914498.3505154641, 'median': 216562.07978484986, 'min': 288.74943971313314, 'max': 7218735.992828329, 'std_dev': 2227216.678792068, 'count': 10, 'missing_values': 0}\n"
     ]
    }
   ],
   "source": [
    "imputer.age_dollar_amounts(donor_year_cpi = 223.1, imp_year_cpi = 322.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"race_cell == 'White' & sex_cell == 'M'\",\n",
       " \"race_cell == 'White' & sex_cell == 'F'\",\n",
       " \"race_cell == 'Black' & sex_cell == 'M'\",\n",
       " \"race_cell == 'Black' & sex_cell == 'F'\"]"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = ['race_cell','sex_cell']\n",
    "\n",
    "imputer.define_cells(variables)\n",
    "imputer.cell_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(col(\"race_cell\")) == (String(White))]\n",
      "[(col(\"sex_cell\")) == (String(M))]\n",
      "[(col(\"race_cell\")) == (String(White))]\n",
      "[(col(\"sex_cell\")) == (String(F))]\n",
      "[(col(\"race_cell\")) == (String(Black))]\n",
      "[(col(\"sex_cell\")) == (String(M))]\n",
      "[(col(\"race_cell\")) == (String(Black))]\n",
      "[(col(\"sex_cell\")) == (String(F))]\n"
     ]
    }
   ],
   "source": [
    "imputer.generate_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"race_cell == 'White' & sex_cell == 'M'\",\n",
       " \"race_cell == 'White' & sex_cell == 'F'\",\n",
       " \"race_cell == 'Black' & sex_cell == 'M'\",\n",
       " \"race_cell == 'Black' & sex_cell == 'F'\"]"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.cell_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"race_cell == 'White' & sex_cell == 'M'\": shape: (3, 4)\n",
       " ┌───────────┬──────────┬───────────┬────────┐\n",
       " │ race_cell ┆ sex_cell ┆ work_cell ┆ weight │\n",
       " │ ---       ┆ ---      ┆ ---       ┆ ---    │\n",
       " │ str       ┆ str      ┆ i64       ┆ i64    │\n",
       " ╞═══════════╪══════════╪═══════════╪════════╡\n",
       " │ White     ┆ M        ┆ 0         ┆ 3      │\n",
       " │ White     ┆ M        ┆ 0         ┆ 1      │\n",
       " │ White     ┆ M        ┆ 0         ┆ 1      │\n",
       " └───────────┴──────────┴───────────┴────────┘,\n",
       " \"race_cell == 'White' & sex_cell == 'F'\": shape: (3, 4)\n",
       " ┌───────────┬──────────┬───────────┬────────┐\n",
       " │ race_cell ┆ sex_cell ┆ work_cell ┆ weight │\n",
       " │ ---       ┆ ---      ┆ ---       ┆ ---    │\n",
       " │ str       ┆ str      ┆ i64       ┆ i64    │\n",
       " ╞═══════════╪══════════╪═══════════╪════════╡\n",
       " │ White     ┆ F        ┆ 1         ┆ 2      │\n",
       " │ White     ┆ F        ┆ 1         ┆ 2      │\n",
       " │ White     ┆ F        ┆ 1         ┆ 1      │\n",
       " └───────────┴──────────┴───────────┴────────┘,\n",
       " \"race_cell == 'Black' & sex_cell == 'M'\": shape: (3, 4)\n",
       " ┌───────────┬──────────┬───────────┬────────┐\n",
       " │ race_cell ┆ sex_cell ┆ work_cell ┆ weight │\n",
       " │ ---       ┆ ---      ┆ ---       ┆ ---    │\n",
       " │ str       ┆ str      ┆ i64       ┆ i64    │\n",
       " ╞═══════════╪══════════╪═══════════╪════════╡\n",
       " │ Black     ┆ M        ┆ 1         ┆ 1      │\n",
       " │ Black     ┆ M        ┆ 1         ┆ 1      │\n",
       " │ Black     ┆ M        ┆ 1         ┆ 2      │\n",
       " └───────────┴──────────┴───────────┴────────┘,\n",
       " \"race_cell == 'Black' & sex_cell == 'F'\": shape: (5, 4)\n",
       " ┌───────────┬──────────┬───────────┬────────┐\n",
       " │ race_cell ┆ sex_cell ┆ work_cell ┆ weight │\n",
       " │ ---       ┆ ---      ┆ ---       ┆ ---    │\n",
       " │ str       ┆ str      ┆ i64       ┆ i64    │\n",
       " ╞═══════════╪══════════╪═══════════╪════════╡\n",
       " │ Black     ┆ F        ┆ 0         ┆ 3      │\n",
       " │ Black     ┆ F        ┆ 1         ┆ 2      │\n",
       " │ Black     ┆ F        ┆ 1         ┆ 4      │\n",
       " │ Black     ┆ F        ┆ 0         ┆ 3      │\n",
       " │ Black     ┆ F        ┆ 0         ┆ 4      │\n",
       " └───────────┴──────────┴───────────┴────────┘}"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.recipient_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"race_cell == 'White' & sex_cell == 'M'\": shape: (2, 5)\n",
       " ┌───────────────┬───────────┬──────────┬───────────┬────────┐\n",
       " │ donor_assets  ┆ race_cell ┆ sex_cell ┆ work_cell ┆ weight │\n",
       " │ ---           ┆ ---       ┆ ---      ┆ ---       ┆ ---    │\n",
       " │ f64           ┆ str       ┆ str      ┆ i64       ┆ i64    │\n",
       " ╞═══════════════╪═══════════╪══════════╪═══════════╪════════╡\n",
       " │ 288749.439713 ┆ White     ┆ M        ┆ 0         ┆ 2      │\n",
       " │ 14437.471986  ┆ White     ┆ M        ┆ 0         ┆ 2      │\n",
       " └───────────────┴───────────┴──────────┴───────────┴────────┘,\n",
       " \"race_cell == 'White' & sex_cell == 'F'\": shape: (2, 5)\n",
       " ┌───────────────┬───────────┬──────────┬───────────┬────────┐\n",
       " │ donor_assets  ┆ race_cell ┆ sex_cell ┆ work_cell ┆ weight │\n",
       " │ ---           ┆ ---       ┆ ---      ┆ ---       ┆ ---    │\n",
       " │ f64           ┆ str       ┆ str      ┆ i64       ┆ i64    │\n",
       " ╞═══════════════╪═══════════╪══════════╪═══════════╪════════╡\n",
       " │ 144374.719857 ┆ White     ┆ F        ┆ 1         ┆ 1      │\n",
       " │ 288749.439713 ┆ White     ┆ F        ┆ 1         ┆ 2      │\n",
       " └───────────────┴───────────┴──────────┴───────────┴────────┘,\n",
       " \"race_cell == 'Black' & sex_cell == 'M'\": shape: (2, 5)\n",
       " ┌──────────────┬───────────┬──────────┬───────────┬────────┐\n",
       " │ donor_assets ┆ race_cell ┆ sex_cell ┆ work_cell ┆ weight │\n",
       " │ ---          ┆ ---       ┆ ---      ┆ ---       ┆ ---    │\n",
       " │ f64          ┆ str       ┆ str      ┆ i64       ┆ i64    │\n",
       " ╞══════════════╪═══════════╪══════════╪═══════════╪════════╡\n",
       " │ 7.2187e6     ┆ Black     ┆ M        ┆ 1         ┆ 1      │\n",
       " │ 5774.988794  ┆ Black     ┆ M        ┆ 1         ┆ 1      │\n",
       " └──────────────┴───────────┴──────────┴───────────┴────────┘,\n",
       " \"race_cell == 'Black' & sex_cell == 'F'\": shape: (4, 5)\n",
       " ┌───────────────┬───────────┬──────────┬───────────┬────────┐\n",
       " │ donor_assets  ┆ race_cell ┆ sex_cell ┆ work_cell ┆ weight │\n",
       " │ ---           ┆ ---       ┆ ---      ┆ ---       ┆ ---    │\n",
       " │ f64           ┆ str       ┆ str      ┆ i64       ┆ i64    │\n",
       " ╞═══════════════╪═══════════╪══════════╪═══════════╪════════╡\n",
       " │ 28874.943971  ┆ Black     ┆ F        ┆ 0         ┆ 2      │\n",
       " │ 433124.15957  ┆ Black     ┆ F        ┆ 1         ┆ 1      │\n",
       " │ 288.74944     ┆ Black     ┆ F        ┆ 1         ┆ 1      │\n",
       " │ 721873.599283 ┆ Black     ┆ F        ┆ 0         ┆ 2      │\n",
       " └───────────────┴───────────┴──────────┴───────────┴────────┘}"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.donor_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(col(\"race_cell\")) == (String(Black))]\n",
      "[(col(\"sex_cell\")) == (String(F))]\n",
      "[(col(\"work_cell\")) == (dyn int: 0)]\n",
      "[(col(\"race_cell\")) == (String(Black))]\n",
      "[(col(\"sex_cell\")) == (String(F))]\n",
      "[(col(\"work_cell\")) == (dyn int: 1)]\n"
     ]
    }
   ],
   "source": [
    "imputer.split_cell(\"race_cell == 'Black' & sex_cell == 'F'\", \"work_cell\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"race_cell == 'White' & sex_cell == 'M'\",\n",
       " \"race_cell == 'White' & sex_cell == 'F'\",\n",
       " \"race_cell == 'Black' & sex_cell == 'M'\",\n",
       " \"race_cell == 'Black' & sex_cell == 'F' & work_cell == 0\",\n",
       " \"race_cell == 'Black' & sex_cell == 'F' & work_cell == 1\"]"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.cell_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.impute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"race_cell == 'White' & sex_cell == 'M'\": shape: (3, 5)\n",
       " ┌───────────┬──────────┬───────────┬────────┬──────────────────┐\n",
       " │ race_cell ┆ sex_cell ┆ work_cell ┆ weight ┆ imp_donor_assets │\n",
       " │ ---       ┆ ---      ┆ ---       ┆ ---    ┆ ---              │\n",
       " │ str       ┆ str      ┆ i64       ┆ i64    ┆ f64              │\n",
       " ╞═══════════╪══════════╪═══════════╪════════╪══════════════════╡\n",
       " │ White     ┆ M        ┆ 0         ┆ 3      ┆ 288749.439713    │\n",
       " │ White     ┆ M        ┆ 0         ┆ 1      ┆ 14437.471986     │\n",
       " │ White     ┆ M        ┆ 0         ┆ 1      ┆ 288749.439713    │\n",
       " └───────────┴──────────┴───────────┴────────┴──────────────────┘,\n",
       " \"race_cell == 'White' & sex_cell == 'F'\": shape: (3, 5)\n",
       " ┌───────────┬──────────┬───────────┬────────┬──────────────────┐\n",
       " │ race_cell ┆ sex_cell ┆ work_cell ┆ weight ┆ imp_donor_assets │\n",
       " │ ---       ┆ ---      ┆ ---       ┆ ---    ┆ ---              │\n",
       " │ str       ┆ str      ┆ i64       ┆ i64    ┆ f64              │\n",
       " ╞═══════════╪══════════╪═══════════╪════════╪══════════════════╡\n",
       " │ White     ┆ F        ┆ 1         ┆ 2      ┆ 288749.439713    │\n",
       " │ White     ┆ F        ┆ 1         ┆ 2      ┆ 288749.439713    │\n",
       " │ White     ┆ F        ┆ 1         ┆ 1      ┆ 144374.719857    │\n",
       " └───────────┴──────────┴───────────┴────────┴──────────────────┘,\n",
       " \"race_cell == 'Black' & sex_cell == 'M'\": shape: (3, 5)\n",
       " ┌───────────┬──────────┬───────────┬────────┬──────────────────┐\n",
       " │ race_cell ┆ sex_cell ┆ work_cell ┆ weight ┆ imp_donor_assets │\n",
       " │ ---       ┆ ---      ┆ ---       ┆ ---    ┆ ---              │\n",
       " │ str       ┆ str      ┆ i64       ┆ i64    ┆ f64              │\n",
       " ╞═══════════╪══════════╪═══════════╪════════╪══════════════════╡\n",
       " │ Black     ┆ M        ┆ 1         ┆ 1      ┆ 5774.988794      │\n",
       " │ Black     ┆ M        ┆ 1         ┆ 1      ┆ 7.2187e6         │\n",
       " │ Black     ┆ M        ┆ 1         ┆ 2      ┆ 5774.988794      │\n",
       " └───────────┴──────────┴───────────┴────────┴──────────────────┘,\n",
       " \"race_cell == 'Black' & sex_cell == 'F' & work_cell == 0\": shape: (3, 5)\n",
       " ┌───────────┬──────────┬───────────┬────────┬──────────────────┐\n",
       " │ race_cell ┆ sex_cell ┆ work_cell ┆ weight ┆ imp_donor_assets │\n",
       " │ ---       ┆ ---      ┆ ---       ┆ ---    ┆ ---              │\n",
       " │ str       ┆ str      ┆ i64       ┆ i64    ┆ f64              │\n",
       " ╞═══════════╪══════════╪═══════════╪════════╪══════════════════╡\n",
       " │ Black     ┆ F        ┆ 0         ┆ 3      ┆ 721873.599283    │\n",
       " │ Black     ┆ F        ┆ 0         ┆ 3      ┆ 28874.943971     │\n",
       " │ Black     ┆ F        ┆ 0         ┆ 4      ┆ 721873.599283    │\n",
       " └───────────┴──────────┴───────────┴────────┴──────────────────┘,\n",
       " \"race_cell == 'Black' & sex_cell == 'F' & work_cell == 1\": shape: (2, 5)\n",
       " ┌───────────┬──────────┬───────────┬────────┬──────────────────┐\n",
       " │ race_cell ┆ sex_cell ┆ work_cell ┆ weight ┆ imp_donor_assets │\n",
       " │ ---       ┆ ---      ┆ ---       ┆ ---    ┆ ---              │\n",
       " │ str       ┆ str      ┆ i64       ┆ i64    ┆ f64              │\n",
       " ╞═══════════╪══════════╪═══════════╪════════╪══════════════════╡\n",
       " │ Black     ┆ F        ┆ 1         ┆ 2      ┆ 288.74944        │\n",
       " │ Black     ┆ F        ┆ 1         ┆ 4      ┆ 288.74944        │\n",
       " └───────────┴──────────┴───────────┴────────┴──────────────────┘}"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.recipient_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (14, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>race_cell</th><th>sex_cell</th><th>work_cell</th><th>weight</th><th>imp_donor_assets</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;White&quot;</td><td>&quot;M&quot;</td><td>0</td><td>3</td><td>288749.439713</td></tr><tr><td>&quot;White&quot;</td><td>&quot;M&quot;</td><td>0</td><td>1</td><td>14437.471986</td></tr><tr><td>&quot;White&quot;</td><td>&quot;M&quot;</td><td>0</td><td>1</td><td>288749.439713</td></tr><tr><td>&quot;White&quot;</td><td>&quot;F&quot;</td><td>1</td><td>2</td><td>288749.439713</td></tr><tr><td>&quot;White&quot;</td><td>&quot;F&quot;</td><td>1</td><td>2</td><td>288749.439713</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Black&quot;</td><td>&quot;F&quot;</td><td>0</td><td>3</td><td>721873.599283</td></tr><tr><td>&quot;Black&quot;</td><td>&quot;F&quot;</td><td>0</td><td>3</td><td>28874.943971</td></tr><tr><td>&quot;Black&quot;</td><td>&quot;F&quot;</td><td>0</td><td>4</td><td>721873.599283</td></tr><tr><td>&quot;Black&quot;</td><td>&quot;F&quot;</td><td>1</td><td>2</td><td>288.74944</td></tr><tr><td>&quot;Black&quot;</td><td>&quot;F&quot;</td><td>1</td><td>4</td><td>288.74944</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (14, 5)\n",
       "┌───────────┬──────────┬───────────┬────────┬──────────────────┐\n",
       "│ race_cell ┆ sex_cell ┆ work_cell ┆ weight ┆ imp_donor_assets │\n",
       "│ ---       ┆ ---      ┆ ---       ┆ ---    ┆ ---              │\n",
       "│ str       ┆ str      ┆ i64       ┆ i64    ┆ f64              │\n",
       "╞═══════════╪══════════╪═══════════╪════════╪══════════════════╡\n",
       "│ White     ┆ M        ┆ 0         ┆ 3      ┆ 288749.439713    │\n",
       "│ White     ┆ M        ┆ 0         ┆ 1      ┆ 14437.471986     │\n",
       "│ White     ┆ M        ┆ 0         ┆ 1      ┆ 288749.439713    │\n",
       "│ White     ┆ F        ┆ 1         ┆ 2      ┆ 288749.439713    │\n",
       "│ White     ┆ F        ┆ 1         ┆ 2      ┆ 288749.439713    │\n",
       "│ …         ┆ …        ┆ …         ┆ …      ┆ …                │\n",
       "│ Black     ┆ F        ┆ 0         ┆ 3      ┆ 721873.599283    │\n",
       "│ Black     ┆ F        ┆ 0         ┆ 3      ┆ 28874.943971     │\n",
       "│ Black     ┆ F        ┆ 0         ┆ 4      ┆ 721873.599283    │\n",
       "│ Black     ┆ F        ┆ 1         ┆ 2      ┆ 288.74944        │\n",
       "│ Black     ┆ F        ┆ 1         ┆ 4      ┆ 288.74944        │\n",
       "└───────────┴──────────┴───────────┴────────┴──────────────────┘"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.recipient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.apply_random_noise(variation_stdev = (1/6), floor_noise = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "The directory '' does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[827], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_analysis_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhot_deck_stats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[809], line 285\u001b[0m, in \u001b[0;36mHotDeckImputer.gen_analysis_file\u001b[1;34m(self, out_file, out_path)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# Ensure the output directory exists\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(out_path):\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe directory \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# Construct the full file path\u001b[39;00m\n\u001b[0;32m    288\u001b[0m full_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(out_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: The directory '' does not exist."
     ]
    }
   ],
   "source": [
    "imputer.gen_analysis_file('hot_deck_stats', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.gen_analysis_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
